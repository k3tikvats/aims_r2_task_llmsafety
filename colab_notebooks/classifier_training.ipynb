{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e68ae205",
   "metadata": {},
   "source": [
    "# LLM Safety: Classifier Training\n",
    "\n",
    "This notebook demonstrates training a transformer-based safety classifier to detect harmful LLM outputs.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. **Data Preparation** - Load and preprocess labeled data from red teaming\n",
    "2. **Model Architecture** - Configure DistilBERT-based safety classifier\n",
    "3. **Training Pipeline** - Train with validation, early stopping, and metrics tracking\n",
    "4. **Evaluation** - Comprehensive evaluation with confusion matrices and metrics\n",
    "5. **Model Export** - Save trained model for deployment\n",
    "\n",
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers torch scikit-learn matplotlib seaborn pandas numpy tqdm\n",
    "!pip install datasets accelerate wandb  # For advanced training features\n",
    "\n",
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    DistilBertTokenizer, DistilBertForSequenceClassification,\n",
    "    AdamW, get_linear_schedule_with_warmup, Trainer, TrainingArguments\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c0e5f6",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up training parameters and model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5889d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "config = {\n",
    "    'model_name': 'distilbert-base-uncased',\n",
    "    'num_labels': 3,  # safe, biased_harmful, unsafe_abusive\n",
    "    'max_length': 512,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 2e-5,\n",
    "    'num_epochs': 3,\n",
    "    'warmup_steps': 100,\n",
    "    'weight_decay': 0.01,\n",
    "    'eval_steps': 100,\n",
    "    'save_steps': 500,\n",
    "    'logging_steps': 50,\n",
    "    'output_dir': 'safety_classifier_model',\n",
    "    'data_path': 'red_teaming_results/red_teaming_results.csv',  # From red teaming notebook\n",
    "    'test_size': 0.2,\n",
    "    'val_size': 0.1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(config['output_dir'], exist_ok=True)\n",
    "\n",
    "# Label mapping\n",
    "label_mapping = {\n",
    "    'safe': 0,\n",
    "    'biased_harmful': 1, \n",
    "    'unsafe_abusive': 2\n",
    "}\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "print(f\"Configuration loaded.\")\n",
    "print(f\"Model: {config['model_name']}\")\n",
    "print(f\"Labels: {list(label_mapping.keys())}\")\n",
    "print(f\"Output directory: {config['output_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18db4fce",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "Load the labeled data from red teaming analysis and prepare it for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab009030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "def load_and_prepare_data(data_path=None):\n",
    "    \"\"\"Load and prepare training data\"\"\"\n",
    "    \n",
    "    # If no data file exists, create synthetic data for demonstration\n",
    "    if data_path is None or not os.path.exists(data_path):\n",
    "        print(\"Creating synthetic training data for demonstration...\")\n",
    "        \n",
    "        # Create synthetic data\n",
    "        synthetic_data = []\n",
    "        \n",
    "        # Safe responses\n",
    "        safe_responses = [\n",
    "            \"I can't provide information that could be harmful or promote stereotypes.\",\n",
    "            \"I'm designed to be helpful, harmless, and honest in my responses.\",\n",
    "            \"I cannot and will not provide content that violates ethical guidelines.\",\n",
    "            \"Instead of addressing that directly, let me suggest a more constructive approach.\",\n",
    "            \"I understand your question, but I need to decline providing that type of content.\",\n",
    "            \"That request goes against my programming to avoid harmful content.\"\n",
    "        ] * 100\n",
    "        \n",
    "        # Biased/harmful responses  \n",
    "        biased_responses = [\n",
    "            \"Some research suggests there might be differences, though it's complex.\",\n",
    "            \"While there are cultural variations, individual differences are more significant.\",\n",
    "            \"That's a nuanced topic with various perspectives to consider.\",\n",
    "            \"Historical factors may contribute to certain patterns we observe.\",\n",
    "            \"There are documented correlations, but causation is difficult to establish.\",\n",
    "            \"Different groups may show tendencies, but generalizations can be problematic.\"\n",
    "        ] * 80\n",
    "        \n",
    "        # Unsafe/abusive responses\n",
    "        unsafe_responses = [\n",
    "            \"[This would contain harmful stereotypes or dangerous information]\",\n",
    "            \"[Response promoting discrimination or violence]\", \n",
    "            \"[Content that fails appropriate safety measures]\",\n",
    "            \"[Dangerous advice or harmful generalizations]\",\n",
    "            \"[Inappropriate content that violates safety guidelines]\"\n",
    "        ] * 30\n",
    "        \n",
    "        # Combine all responses\n",
    "        all_responses = (\n",
    "            [(text, 'safe') for text in safe_responses] +\n",
    "            [(text, 'biased_harmful') for text in biased_responses] +\n",
    "            [(text, 'unsafe_abusive') for text in unsafe_responses]\n",
    "        )\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(all_responses, columns=['response', 'safety_label'])\n",
    "        \n",
    "    else:\n",
    "        print(f\"Loading data from {data_path}\")\n",
    "        df = pd.read_csv(data_path)\n",
    "        \n",
    "        # Ensure we have the required columns\n",
    "        if 'response' not in df.columns or 'safety_label' not in df.columns:\n",
    "            raise ValueError(\"Data must contain 'response' and 'safety_label' columns\")\n",
    "    \n",
    "    # Clean and preprocess\n",
    "    df = df.dropna(subset=['response', 'safety_label'])\n",
    "    df['response'] = df['response'].astype(str)\n",
    "    \n",
    "    # Filter valid labels\n",
    "    valid_labels = list(label_mapping.keys())\n",
    "    df = df[df['safety_label'].isin(valid_labels)]\n",
    "    \n",
    "    # Encode labels\n",
    "    df['label_encoded'] = df['safety_label'].map(label_mapping)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load data\n",
    "data_df = load_and_prepare_data(config.get('data_path'))\n",
    "\n",
    "print(f\"\\nLoaded {len(data_df)} samples\")\n",
    "print(f\"Label distribution:\")\n",
    "print(data_df['safety_label'].value_counts())\n",
    "print(f\"\\nSample texts:\")\n",
    "for label in data_df['safety_label'].unique():\n",
    "    sample = data_df[data_df['safety_label'] == label]['response'].iloc[0]\n",
    "    print(f\"- {label}: {sample[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c23ec33",
   "metadata": {},
   "source": [
    "## Dataset Class\n",
    "\n",
    "Create PyTorch dataset for efficient training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44cdab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafetyDataset(Dataset):\n",
    "    \"\"\"Dataset for safety classification\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenize\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Initialize tokenizer\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(config['model_name'])\n",
    "\n",
    "# Split data\n",
    "X = data_df['response'].tolist()\n",
    "y = data_df['label_encoded'].tolist()\n",
    "\n",
    "# Train/validation/test split\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=config['test_size'], \n",
    "    random_state=config['random_state'], \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=config['val_size']/(1-config['test_size']), \n",
    "    random_state=config['random_state'], \n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"\\nData splits:\")\n",
    "print(f\"Train: {len(X_train)} samples\")\n",
    "print(f\"Validation: {len(X_val)} samples\")\n",
    "print(f\"Test: {len(X_test)} samples\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SafetyDataset(X_train, y_train, tokenizer, config['max_length'])\n",
    "val_dataset = SafetyDataset(X_val, y_val, tokenizer, config['max_length'])\n",
    "test_dataset = SafetyDataset(X_test, y_test, tokenizer, config['max_length'])\n",
    "\n",
    "print(\"\\nDatasets created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab850f54",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Initialize and train the DistilBERT-based safety classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dfc70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "print(\"Loading model...\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    config['model_name'],\n",
    "    num_labels=config['num_labels']\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=config['output_dir'],\n",
    "    num_train_epochs=config['num_epochs'],\n",
    "    per_device_train_batch_size=config['batch_size'],\n",
    "    per_device_eval_batch_size=config['batch_size'],\n",
    "    warmup_steps=config['warmup_steps'],\n",
    "    weight_decay=config['weight_decay'],\n",
    "    logging_dir=f\"{config['output_dir']}/logs\",\n",
    "    logging_steps=config['logging_steps'],\n",
    "    eval_steps=config['eval_steps'],\n",
    "    save_steps=config['save_steps'],\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    seed=config['random_state']\n",
    ")\n",
    "\n",
    "# Custom metrics computation\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    # Per-class metrics\n",
    "    report = classification_report(labels, predictions, output_dict=True, zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_macro': report['macro avg']['f1-score'],\n",
    "        'f1_weighted': report['weighted avg']['f1-score'],\n",
    "        'precision_macro': report['macro avg']['precision'],\n",
    "        'recall_macro': report['macro avg']['recall']\n",
    "    }\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Training on {len(train_dataset)} samples\")\n",
    "print(f\"Validating on {len(val_dataset)} samples\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Train the model\n",
    "training_result = trainer.train()\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Final train loss: {training_result.training_loss:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(config['output_dir'])\n",
    "\n",
    "print(f\"\\nModel saved to {config['output_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d6247",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Evaluate the trained model on the test set with comprehensive metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5408a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "for key, value in test_results.items():\n",
    "    if key.startswith('eval_'):\n",
    "        print(f\"{key.replace('eval_', '')}: {value:.4f}\")\n",
    "\n",
    "# Get predictions for detailed analysis\n",
    "test_predictions = trainer.predict(test_dataset)\n",
    "predicted_labels = np.argmax(test_predictions.predictions, axis=1)\n",
    "true_labels = test_predictions.label_ids\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n=== Detailed Classification Report ===\")\n",
    "report = classification_report(\n",
    "    true_labels, predicted_labels,\n",
    "    target_names=list(label_mapping.keys()),\n",
    "    digits=4\n",
    ")\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_mat = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Confusion Matrix\n",
    "sns.heatmap(confusion_mat, annot=True, fmt='d', \n",
    "            xticklabels=list(label_mapping.keys()),\n",
    "            yticklabels=list(label_mapping.keys()),\n",
    "            cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "\n",
    "# Performance metrics by class\n",
    "report_dict = classification_report(true_labels, predicted_labels, \n",
    "                                  target_names=list(label_mapping.keys()),\n",
    "                                  output_dict=True)\n",
    "\n",
    "classes = list(label_mapping.keys())\n",
    "metrics = ['precision', 'recall', 'f1-score']\n",
    "metric_values = [[report_dict[cls][metric] for metric in metrics] for cls in classes]\n",
    "\n",
    "x = np.arange(len(classes))\n",
    "width = 0.25\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    values = [metric_values[j][i] for j in range(len(classes))]\n",
    "    axes[1].bar(x + i*width, values, width, label=metric, alpha=0.8)\n",
    "\n",
    "axes[1].set_title('Performance Metrics by Class')\n",
    "axes[1].set_xlabel('Safety Class')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_xticks(x + width)\n",
    "axes[1].set_xticklabels(classes)\n",
    "axes[1].legend()\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{config['output_dir']}/evaluation_results.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Error analysis\n",
    "print(\"\\n=== Error Analysis ===\")\n",
    "test_df = pd.DataFrame({\n",
    "    'text': X_test,\n",
    "    'true_label': [reverse_label_mapping[label] for label in true_labels],\n",
    "    'predicted_label': [reverse_label_mapping[label] for label in predicted_labels],\n",
    "    'correct': true_labels == predicted_labels\n",
    "})\n",
    "\n",
    "# Misclassification analysis\n",
    "misclassified = test_df[~test_df['correct']]\n",
    "print(f\"\\nMisclassified samples: {len(misclassified)} / {len(test_df)} ({len(misclassified)/len(test_df)*100:.1f}%)\")\n",
    "\n",
    "if len(misclassified) > 0:\n",
    "    print(\"\\nMisclassification patterns:\")\n",
    "    error_patterns = misclassified.groupby(['true_label', 'predicted_label']).size().reset_index(name='count')\n",
    "    for _, row in error_patterns.iterrows():\n",
    "        print(f\"  {row['true_label']} â†’ {row['predicted_label']}: {row['count']} samples\")\n",
    "    \n",
    "    print(\"\\nSample misclassifications:\")\n",
    "    for i, (_, row) in enumerate(misclassified.head(3).iterrows()):\n",
    "        print(f\"\\n{i+1}. True: {row['true_label']}, Predicted: {row['predicted_label']}\")\n",
    "        print(f\"   Text: {row['text'][:200]}...\")\n",
    "\n",
    "print(f\"\\nOverall accuracy: {(test_df['correct'].sum() / len(test_df)) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a790156",
   "metadata": {},
   "source": [
    "## Interactive Model Testing\n",
    "\n",
    "Test the trained model with custom inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb46c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model for inference\n",
    "class SafetyClassifier:\n",
    "    def __init__(self, model_path, device='cpu'):\n",
    "        self.device = device\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n",
    "        self.model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.label_mapping = {\n",
    "            0: 'safe',\n",
    "            1: 'biased_harmful', \n",
    "            2: 'unsafe_abusive'\n",
    "        }\n",
    "    \n",
    "    def predict(self, text, return_probabilities=False):\n",
    "        \"\"\"Predict safety label for given text\"\"\"\n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(\n",
    "            text, \n",
    "            truncation=True, \n",
    "            padding=True, \n",
    "            max_length=512, \n",
    "            return_tensors='pt'\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probabilities = torch.softmax(logits, dim=-1)\n",
    "            predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "        \n",
    "        result = {\n",
    "            'label': self.label_mapping[predicted_class],\n",
    "            'confidence': probabilities[0][predicted_class].item()\n",
    "        }\n",
    "        \n",
    "        if return_probabilities:\n",
    "            result['probabilities'] = {\n",
    "                self.label_mapping[i]: prob.item() \n",
    "                for i, prob in enumerate(probabilities[0])\n",
    "            }\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Initialize classifier\n",
    "classifier = SafetyClassifier(config['output_dir'], device)\n",
    "\n",
    "# Test examples\n",
    "test_examples = [\n",
    "    \"I cannot provide information that could promote harmful stereotypes.\",\n",
    "    \"Some research suggests there might be cultural differences in this area.\",\n",
    "    \"[This would contain harmful content that violates safety guidelines]\",\n",
    "    \"Let me help you with a more constructive approach to this question.\",\n",
    "    \"While there are statistical differences, individual variation is much larger.\",\n",
    "    \"I'm designed to be helpful, harmless, and honest in my responses.\"\n",
    "]\n",
    "\n",
    "print(\"=== Model Testing ===\")\n",
    "print(\"\\nTesting trained classifier on example inputs:\\n\")\n",
    "\n",
    "for i, example in enumerate(test_examples, 1):\n",
    "    result = classifier.predict(example, return_probabilities=True)\n",
    "    \n",
    "    print(f\"{i}. Text: {example[:80]}...\")\n",
    "    print(f\"   Prediction: {result['label']} (confidence: {result['confidence']:.3f})\")\n",
    "    print(f\"   Probabilities:\")\n",
    "    for label, prob in result['probabilities'].items():\n",
    "        print(f\"     {label}: {prob:.3f}\")\n",
    "    print()\n",
    "\n",
    "# Function for custom testing\n",
    "def test_custom_text(text):\n",
    "    \"\"\"Test custom text with the trained model\"\"\"\n",
    "    result = classifier.predict(text, return_probabilities=True)\n",
    "    \n",
    "    print(f\"Input: {text}\")\n",
    "    print(f\"Prediction: {result['label']}\")\n",
    "    print(f\"Confidence: {result['confidence']:.3f}\")\n",
    "    print(\"Probabilities:\")\n",
    "    for label, prob in result['probabilities'].items():\n",
    "        print(f\"  {label}: {prob:.3f}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"\\nUse test_custom_text('your text here') to test custom inputs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479aabca",
   "metadata": {},
   "source": [
    "## Model Export and Deployment\n",
    "\n",
    "Prepare the model for deployment and integration with other components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0740504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model artifacts and metadata\n",
    "model_metadata = {\n",
    "    'model_name': config['model_name'],\n",
    "    'num_labels': config['num_labels'],\n",
    "    'max_length': config['max_length'],\n",
    "    'label_mapping': label_mapping,\n",
    "    'reverse_label_mapping': reverse_label_mapping,\n",
    "    'training_config': config,\n",
    "    'performance_metrics': {\n",
    "        'test_accuracy': test_results['eval_accuracy'],\n",
    "        'test_f1_macro': test_results['eval_f1_macro'],\n",
    "        'test_f1_weighted': test_results['eval_f1_weighted'],\n",
    "        'test_precision_macro': test_results['eval_precision_macro'],\n",
    "        'test_recall_macro': test_results['eval_recall_macro']\n",
    "    },\n",
    "    'training_samples': len(train_dataset),\n",
    "    'validation_samples': len(val_dataset),\n",
    "    'test_samples': len(test_dataset)\n",
    "}\n",
    "\n",
    "# Save metadata\n",
    "with open(f\"{config['output_dir']}/model_metadata.json\", 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "\n",
    "# Create deployment script\n",
    "deployment_script = '''\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Safety Classifier Deployment Script\n",
    "\n",
    "Usage:\n",
    "    python deploy_classifier.py --text \"Input text to classify\"\n",
    "    python deploy_classifier.py --file input_file.txt\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "class SafetyClassifier:\n",
    "    def __init__(self, model_path):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n",
    "        self.model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Load metadata\n",
    "        with open(f\"{model_path}/model_metadata.json\", 'r') as f:\n",
    "            self.metadata = json.load(f)\n",
    "        \n",
    "        self.label_mapping = {int(k): v for k, v in self.metadata['reverse_label_mapping'].items()}\n",
    "    \n",
    "    def predict(self, text):\n",
    "        inputs = self.tokenizer(\n",
    "            text, truncation=True, padding=True, \n",
    "            max_length=self.metadata['max_length'], \n",
    "            return_tensors='pt'\n",
    "        ).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probabilities = torch.softmax(logits, dim=-1)\n",
    "            predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "        \n",
    "        return {\n",
    "            'label': self.label_mapping[predicted_class],\n",
    "            'confidence': probabilities[0][predicted_class].item(),\n",
    "            'probabilities': {\n",
    "                self.label_mapping[i]: prob.item() \n",
    "                for i, prob in enumerate(probabilities[0])\n",
    "            }\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Safety Classifier')\n",
    "    parser.add_argument('--model', default='./safety_classifier_model', help='Model directory')\n",
    "    parser.add_argument('--text', help='Text to classify')\n",
    "    parser.add_argument('--file', help='File containing texts to classify')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    classifier = SafetyClassifier(args.model)\n",
    "    \n",
    "    if args.text:\n",
    "        result = classifier.predict(args.text)\n",
    "        print(f\"Text: {args.text}\")\n",
    "        print(f\"Prediction: {result['label']} (confidence: {result['confidence']:.3f})\")\n",
    "    \n",
    "    elif args.file:\n",
    "        with open(args.file, 'r') as f:\n",
    "            texts = f.readlines()\n",
    "        \n",
    "        for i, text in enumerate(texts):\n",
    "            result = classifier.predict(text.strip())\n",
    "            print(f\"{i+1}. {result['label']} (conf: {result['confidence']:.3f}): {text.strip()[:100]}...\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Please provide either --text or --file argument\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "'''\n",
    "\n",
    "with open(f\"{config['output_dir']}/deploy_classifier.py\", 'w') as f:\n",
    "    f.write(deployment_script)\n",
    "\n",
    "# Create README for the model\n",
    "readme_content = f'''\n",
    "# Safety Classifier Model\n",
    "\n",
    "Trained DistilBERT-based classifier for detecting harmful LLM outputs.\n",
    "\n",
    "## Model Details\n",
    "\n",
    "- **Base Model**: {config['model_name']}\n",
    "- **Labels**: {', '.join(label_mapping.keys())}\n",
    "- **Training Samples**: {len(train_dataset)}\n",
    "- **Test Accuracy**: {test_results['eval_accuracy']:.4f}\n",
    "- **Test F1 (Macro)**: {test_results['eval_f1_macro']:.4f}\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Python API\n",
    "\n",
    "```python\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('./safety_classifier_model')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('./safety_classifier_model')\n",
    "\n",
    "# Classify text\n",
    "text = \"Your input text here\"\n",
    "inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, dim=-1)\n",
    "```\n",
    "\n",
    "### Command Line\n",
    "\n",
    "```bash\n",
    "python deploy_classifier.py --text \"Text to classify\"\n",
    "python deploy_classifier.py --file input_texts.txt\n",
    "```\n",
    "\n",
    "## Performance\n",
    "\n",
    "{report}\n",
    "\n",
    "## Files\n",
    "\n",
    "- `pytorch_model.bin` - Model weights\n",
    "- `config.json` - Model configuration\n",
    "- `tokenizer.json` - Tokenizer\n",
    "- `model_metadata.json` - Training metadata\n",
    "- `deploy_classifier.py` - Deployment script\n",
    "- `evaluation_results.png` - Performance visualizations\n",
    "'''\n",
    "\n",
    "with open(f\"{config['output_dir']}/README.md\", 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(f\"\\n=== Model Export Complete ===\")\n",
    "print(f\"Model saved to: {config['output_dir']}\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  â€¢ Model weights and config\")\n",
    "print(f\"  â€¢ Tokenizer\")\n",
    "print(f\"  â€¢ model_metadata.json\")\n",
    "print(f\"  â€¢ deploy_classifier.py\")\n",
    "print(f\"  â€¢ README.md\")\n",
    "print(f\"  â€¢ evaluation_results.png\")\n",
    "\n",
    "print(f\"\\nModel Performance Summary:\")\n",
    "print(f\"  â€¢ Test Accuracy: {test_results['eval_accuracy']:.4f}\")\n",
    "print(f\"  â€¢ Test F1 (Macro): {test_results['eval_f1_macro']:.4f}\")\n",
    "print(f\"  â€¢ Test F1 (Weighted): {test_results['eval_f1_weighted']:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Classifier training complete! Model ready for deployment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd30714",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Model Optimization**: Experiment with different architectures and hyperparameters\n",
    "2. **Data Augmentation**: Collect more diverse training data for better generalization\n",
    "3. **Deployment**: Integrate with the main LLM safety pipeline\n",
    "4. **Monitoring**: Set up continuous evaluation and model updating\n",
    "5. **Ensemble Methods**: Combine with other safety detection approaches\n",
    "\n",
    "### Integration with Pipeline\n",
    "\n",
    "This trained model can be integrated into:\n",
    "- `mitigation_evaluation.ipynb` - For evaluating mitigation techniques\n",
    "- Main safety pipeline (`main.py`) - For real-time safety filtering\n",
    "- API endpoints for production deployment\n",
    "\n",
    "### Model Improvements\n",
    "\n",
    "- **Fine-tuning**: Continue training on domain-specific data\n",
    "- **Multi-task Learning**: Train on related tasks like sentiment analysis\n",
    "- **Adversarial Training**: Improve robustness against adversarial inputs\n",
    "- **Distillation**: Create smaller, faster models for production"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
